{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"example_spam.csv\",delimiter=\",\",names = ['label','message'])\n",
    "\n",
    "#Uploading dataset from biggie\n",
    "biggie_df = pd.read_csv('./biggie_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "biggie_df.columns = ['lyrics']\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.lower()\n",
    "\n",
    "#Uploading dataset from 2pac\n",
    "pac_df = pd.read_csv('./2pac_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "pac_df.columns = ['lyrics']\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesBiggie,values2pac = biggie_df.get_values(),pac_df.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggie_lyrics = biggie_df['lyrics'].values\n",
    "biggie_lyrics = [song.split('\\n') for song in biggie_lyrics]\n",
    "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
    "pac_lyrics = pac_df['lyrics'].values\n",
    "pac_lyrics = [song.split('\\n') for song in pac_lyrics]\n",
    "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
    "\n",
    "rap_lines = []\n",
    "\n",
    "for line in biggie_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([0,line]))\n",
    "\n",
    "for line in pac_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([1,line]))\n",
    "\n",
    "rap_lines = np.array(rap_lines)\n",
    "\n",
    "#Getting the dataframe\n",
    "df = pd.DataFrame(rap_lines)\n",
    "df.columns = ['label','line']\n",
    "df.head()\n",
    "df['label'] = df['label'].replace(['0','1'],[0,1])\n",
    "\n",
    "values = df.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in lower-case for rap lines\n",
      "0                                     fuck all you hoes\\r\n",
      "1                               get a grip motherfucker\\r\n",
      "2       yeah this album is dedicated to all the teache...\n",
      "3       id never amount to nothin to all the people th...\n",
      "4       buildings that i was hustlin in front of that ...\n",
      "5       me when i was just tryin to make some money to...\n",
      "6       and all the niggas in the struggle you know wh...\n",
      "7                      uhha its all good baby baybee uh\\r\n",
      "8                                    it was all a dream\\r\n",
      "9                       i used to read word up magazine\\r\n",
      "10            saltnpepa and heavy d up in the limousine\\r\n",
      "11                           hangin pictures on my wall\\r\n",
      "12       every saturday rap attack mr magic marley marl\\r\n",
      "13                   i let my tape rock til my tape pop\\r\n",
      "14       smokin weed and bamboo sippin on private stock\\r\n",
      "15      way back when i had the red and black lumberja...\n",
      "16                                with the hat to match\\r\n",
      "17                     remember rappin duke duhha duhha\\r\n",
      "18      you never thought that hip hop would take it t...\n",
      "19          now im in the limelight cause i rhyme tight\\r\n",
      "20        time to get paid blow up like the world trade\\r\n",
      "21                 born sinner the opposite of a winner\\r\n",
      "22      remember when i used to eat sardines for dinner\\r\n",
      "23                    peace to ron g brucey b kid capri\\r\n",
      "24                      funkmaster flex lovebug starsky\\r\n",
      "25                im blowin up like you thought i would\\r\n",
      "26                  call the crib same number same hood\\r\n",
      "27        uh and if you dont know now you know nigga uh\\r\n",
      "28                       you know very well who you are\\r\n",
      "29        dont let em hold you down reach for the stars\\r\n",
      "                              ...                        \n",
      "1940                dont let em jack you up back you up\\r\n",
      "1941                  crack you up and pimpsmack you up\\r\n",
      "1942                   you gotta learn to hold your own\\r\n",
      "1943    they get jealous when they see you with your m...\n",
      "1944             but tell the cops they cant touch this\\r\n",
      "1945    i dont trust this when they try to rush i bust...\n",
      "1946                         thats the sound of my tool\\r\n",
      "1947    you say it aint cool my mama didnt raise no fo...\n",
      "1948    and as long as i stay black i gotta stay strap...\n",
      "1949                        and i never get to lay back\\r\n",
      "1950       cause i always got to worry bout the payback\\r\n",
      "1951               some buck that i roughed up way back\\r\n",
      "1952                  coming back after all these years\\r\n",
      "1953                 ratatattattattat thats the way it is\n",
      "1954    out on bail fresh out of jail california dream...\n",
      "1955    soon as i step on the scene im hearing hoochie...\n",
      "1956                     fiending for money and alcohol\\r\n",
      "1957    the life of a westside player where cowards di...\n",
      "1958    only in cali where we riot not rally to live a...\n",
      "1959    in la we wearing chucks not ballys yeah thats ...\n",
      "1960    dressed in locs and khaki suits and ride is wh...\n",
      "1961    flossing but have caution we collide with othe...\n",
      "1962                          famous because we program\\r\n",
      "1963    worldwide let them recognize from long beach t...\n",
      "1964    bumping and grinding like a slow jam its wests...\n",
      "1965        so you know the row wont bow down to no man\\r\n",
      "1966    say what you say but give me that bomb beat fr...\n",
      "1967                  let me serenade the streets of la\\r\n",
      "1968    from oakland to sactown the bay area and back ...\n",
      "1969             cali is where they put their mack down\\r\n",
      "Name: line, Length: 1970, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['line'] = df['line'].str.lower()\n",
    "print(\"Lines in lower-case for rap lines\")\n",
    "print(df['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line'] = df['line'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and lines for rap lines\n"
     ]
    }
   ],
   "source": [
    "df['line'] = df['line'].apply(lambda x: ' '.join(x))\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "print(\"Counts and lines for rap lines\")\n",
    "counts = count_vect.fit_transform(df['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer().fit(counts)\n",
    "counts = transformer.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model got 68.02030456852792% Accuracy\n",
      "The model got 68.52791878172589% Accuracy\n",
      "The model got 64.46700507614213% Accuracy\n",
      "The model got 71.06598984771574% Accuracy\n",
      "The model got 70.05076142131979% Accuracy\n",
      "The model got 72.08121827411168% Accuracy\n",
      "The model got 67.00507614213198% Accuracy\n",
      "The model got 70.05076142131979% Accuracy\n",
      "The model got 67.00507614213198% Accuracy\n",
      "The model got 70.55837563451777% Accuracy\n",
      "Average Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(counts, df['label'], test_size=.1)\n",
    "results = []\n",
    "for _ in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(counts, df['label'], test_size=.1)\n",
    "    predicted = model.fit(x_train, y_train)\n",
    "    predicted = model.predict(x_test)\n",
    "    res = (np.mean(predicted == y_test))\n",
    "    print(\"The model got \" + str(100*res) + \"% Accuracy\")\n",
    "    results.append(res)\n",
    "    \n",
    "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
