{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"example_131.csv\",delimiter=\",\",names = ['label','message']) #Loading the data from example 13.1\n",
    "df2 = pd.read_csv(\"example_1310.csv\",delimiter=\",\",names = ['label','message']) #Loading the data from example 13.10\n",
    "df3 = pd.read_csv(\"example_spam.csv\",delimiter=\",\",names = ['label','message']) #Loading the data from example spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,values2,values3 = df.get_values(),df2.get_values(),df3.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].str.lower()\n",
    "df2['message'] = df2['message'].str.lower()\n",
    "df3['message'] = df3['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(nltk.word_tokenize)\n",
    "df2['message'] = df2['message'].apply(nltk.word_tokenize)\n",
    "df3['message'] = df3['message'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "df2['message'] = df2['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "df3['message'] = df3['message'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "df2['message'] = df2['message'].apply(lambda x: ' '.join(x))\n",
    "df3['message'] = df3['message'].apply(lambda x: ' '.join(x))\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and messages for the example 13.1\n",
      "['beij', 'chines', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "[[1 2 0 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]\n",
      " [0 3 1 0 0 1]]\n",
      "0                  chines beij chines\n",
      "1              chines chines shanghai\n",
      "2                        chines macao\n",
      "3                  tokyo japan chines\n",
      "4    chines chines chines tokyo japan\n",
      "Name: message, dtype: object\n",
      "\n",
      " Counts and messages for the example 13.10\n",
      "['japan', 'macao', 'osaka', 'sapporo', 'shanghai', 'taipei', 'taiwan']\n",
      "[[0 0 0 0 0 1 1]\n",
      " [0 1 0 0 1 0 1]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 0 1 1 0 0 1]\n",
      " [0 0 0 1 0 0 2]]\n",
      "0            taipei taiwan\n",
      "1    macao taiwan shanghai\n",
      "2            japan sapporo\n",
      "3     sapporo osaka taiwan\n",
      "4    taiwan taiwan sapporo\n",
      "Name: message, dtype: object\n",
      "\n",
      " Counts and messages for the example spam detection\n",
      "['now', 'password', 'review', 'send', 'us', 'your']\n",
      "[[0 1 0 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 1 0 0 1]\n",
      " [0 0 1 0 1 0]\n",
      " [0 1 0 1 0 1]\n",
      " [0 1 0 1 1 1]\n",
      " [1 0 1 0 1 0]]\n",
      "0    send us your password\n",
      "1      send us your review\n",
      "2     review your password\n",
      "3                review us\n",
      "4       send your password\n",
      "5    send us your password\n",
      "6            review us now\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts and messages for the example 13.1\")\n",
    "counts = count_vect.fit_transform(df['message'])\n",
    "print(count_vect.get_feature_names())\n",
    "print(counts.toarray())\n",
    "print(df['message'])\n",
    "\n",
    "print(\"\\n Counts and messages for the example 13.10\")\n",
    "counts2 = count_vect.fit_transform(df2['message'])\n",
    "print(count_vect.get_feature_names())\n",
    "print(counts2.toarray())\n",
    "print(df2['message'])\n",
    "\n",
    "print(\"\\n Counts and messages for the example spam detection\")\n",
    "counts3 = count_vect.fit_transform(df3['message'])\n",
    "print(count_vect.get_feature_names())\n",
    "print(counts3.toarray())\n",
    "print(df3['message'])\n",
    "\n",
    "transformer = TfidfTransformer().fit(counts)\n",
    "counts = transformer.transform(counts)\n",
    "transformer2 = TfidfTransformer().fit(counts2)\n",
    "counts2 = transformer2.transform(counts2)\n",
    "transformer3 = TfidfTransformer().fit(counts3)\n",
    "counts3 = transformer3.transform(counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer().fit(counts)\n",
    "counts = transformer.transform(counts)\n",
    "transformer2 = TfidfTransformer().fit(counts2)\n",
    "counts2 = transformer2.transform(counts2)\n",
    "transformer3 = TfidfTransformer().fit(counts3)\n",
    "counts3 = transformer3.transform(counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = counts[:4]\n",
    "x_test = counts[4:5]\n",
    "y_train = pd.Series(df.get_values()[0:4][:,0])\n",
    "y_test = pd.Series(df.get_values()[4:5][:,0])\n",
    "\n",
    "x_train2 = counts2[:4]\n",
    "x_test2 = counts2[4:5]\n",
    "y_train2 = pd.Series(df2.get_values()[0:4][:,0])\n",
    "y_test2 = pd.Series(df2.get_values()[4:5][:,0])\n",
    "\n",
    "x_train3 = counts3[:6]\n",
    "x_test3 = counts3[6:7]\n",
    "y_train3 = pd.Series(df3.get_values()[0:6][:,0])\n",
    "y_test3 = pd.Series(df3.get_values()[6:7][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the example 13.1. The sample is \"chines chines chines tokyo japan\"\n",
      "Predicted class: ['Not China']\n",
      "Probabilities for each class: [[0.19106679 0.80893321]]\n",
      "\n",
      " Results for the example 13.10. The sample is \"taiwan taiwan sapporo\"\n",
      "Predicted class: ['Not China']\n",
      "Probabilities for each class: [[0.25 0.75]]\n",
      "\n",
      " Results for the example spam detection. The sample is \"review us now\"\n",
      "Predicted class: ['ham']\n",
      "Probabilities for each class: [[0.68109623 0.31890377]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "print(\"Results for the example 13.1. The sample is \\\"\" + str(df['message'][4])+ \"\\\"\")\n",
    "print(\"Predicted class: \" + str(predicted))\n",
    "print(\"Probabilities for each class: \" + str(model.predict_proba(x_test)))\n",
    "\n",
    "model.fit(x_train2, y_train2)\n",
    "predicted2 = model.predict(x_test2)\n",
    "print(\"\\n Results for the example 13.10. The sample is \\\"\" + str(df2['message'][4])+ \"\\\"\")\n",
    "print(\"Predicted class: \" + str(predicted2))\n",
    "print(\"Probabilities for each class: \" + str(model.predict_proba(x_test2)))\n",
    "\n",
    "model.fit(x_train3, y_train3)\n",
    "predicted3 = model.predict(x_test3)\n",
    "print(\"\\n Results for the example spam detection. The sample is \\\"\" + str(df3['message'][6]) + \"\\\"\")\n",
    "print(\"Predicted class: \" + str(predicted3))\n",
    "print(\"Probabilities for each class: \" + str(model.predict_proba(x_test3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
