{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"example_131.csv\",delimiter=\",\",names = ['label','message']) #Loading the data from example 13.1\n",
    "df2 = pd.read_csv(\"example_1310.csv\",delimiter=\",\",names = ['label','message']) #Loading the data from example 13.10\n",
    "df3 = pd.read_csv(\"example_spam.csv\",delimiter=\",\",names = ['label','message']) #Loading the data from example spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,values2,values3 = df.get_values(),df2.get_values(),df3.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for the example 13.1\n",
      "(5, 2)\n",
      "[['China' 'Chinese Beijing Chinese']\n",
      " ['China' 'Chinese Chinese Shanghai']\n",
      " ['China' 'Chinese Macao']\n",
      " ['Not China' 'Tokyo Japan Chinese']\n",
      " ['?' 'Chinese Chinese Chinese Tokyo Japan']]\n",
      "\n",
      " Values for the example 13.10\n",
      "(5, 2)\n",
      "[['China' 'Taipei Taiwan']\n",
      " ['China' 'Macao Taiwan Shanghai']\n",
      " ['Not China' 'Japan Sapporo']\n",
      " ['Not China' 'Sapporo Osaka Taiwan']\n",
      " ['?' 'Taiwan Taiwan Sapporo']]\n",
      "\n",
      " Values for the example spam detection\n",
      "(7, 2)\n",
      "[['spam' 'send us your password']\n",
      " ['ham' 'send us your review']\n",
      " ['ham' 'review your password']\n",
      " ['spam' 'review us']\n",
      " ['spam' 'send your password']\n",
      " ['spam' 'send us your password']\n",
      " ['?' 'review us now']]\n"
     ]
    }
   ],
   "source": [
    "values = df.get_values()\n",
    "print(\"Values for the example 13.1\")\n",
    "print(values.shape)\n",
    "print(values)\n",
    "print(\"\\n Values for the example 13.10\")\n",
    "print(values2.shape)\n",
    "print(values2)\n",
    "print(\"\\n Values for the example spam detection\")\n",
    "print(values3.shape)\n",
    "print(values3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].str.lower()\n",
    "df2['message'] = df2['message'].str.lower()\n",
    "df3['message'] = df3['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Messages after tokenization for the example 13.10\n",
      "0                  [chinese, beijing, chinese]\n",
      "1                 [chinese, chinese, shanghai]\n",
      "2                             [chinese, macao]\n",
      "3                      [tokyo, japan, chinese]\n",
      "4    [chinese, chinese, chinese, tokyo, japan]\n",
      "Name: message, dtype: object\n",
      "\n",
      " Messages after tokenization for the example 13.1\n",
      "0             [taipei, taiwan]\n",
      "1    [macao, taiwan, shanghai]\n",
      "2             [japan, sapporo]\n",
      "3     [sapporo, osaka, taiwan]\n",
      "4    [taiwan, taiwan, sapporo]\n",
      "Name: message, dtype: object\n",
      "\n",
      " Messages after tokenization for the example spam detection\n",
      "0    [send, us, your, password]\n",
      "1      [send, us, your, review]\n",
      "2      [review, your, password]\n",
      "3                  [review, us]\n",
      "4        [send, your, password]\n",
      "5    [send, us, your, password]\n",
      "6             [review, us, now]\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['message'] = df['message'].apply(nltk.word_tokenize)\n",
    "df2['message'] = df2['message'].apply(nltk.word_tokenize)\n",
    "df3['message'] = df3['message'].apply(nltk.word_tokenize)\n",
    "print(\"\\n Messages after tokenization for the example 13.10\")\n",
    "print(df['message'])\n",
    "print(\"\\n Messages after tokenization for the example 13.1\")\n",
    "print(df2['message'])\n",
    "print(\"\\n Messages after tokenization for the example spam detection\")\n",
    "print(df3['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "df2['message'] = df2['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "df3['message'] = df3['message'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and messages for the example 13.1\n",
      "['beij', 'chines', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "[[1 2 0 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]\n",
      " [0 3 1 0 0 1]]\n",
      "0                  chines beij chines\n",
      "1              chines chines shanghai\n",
      "2                        chines macao\n",
      "3                  tokyo japan chines\n",
      "4    chines chines chines tokyo japan\n",
      "Name: message, dtype: object\n",
      "\n",
      " Counts and messages for the example 13.10\n",
      "['japan', 'macao', 'osaka', 'sapporo', 'shanghai', 'taipei', 'taiwan']\n",
      "[[0 0 0 0 0 1 1]\n",
      " [0 1 0 0 1 0 1]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 0 1 1 0 0 1]\n",
      " [0 0 0 1 0 0 2]]\n",
      "0            taipei taiwan\n",
      "1    macao taiwan shanghai\n",
      "2            japan sapporo\n",
      "3     sapporo osaka taiwan\n",
      "4    taiwan taiwan sapporo\n",
      "Name: message, dtype: object\n",
      "\n",
      " Counts and messages for the example spam detection\n",
      "['now', 'password', 'review', 'send', 'us', 'your']\n",
      "[[0 1 0 1 1 1]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 1 0 0 1]\n",
      " [0 0 1 0 1 0]\n",
      " [0 1 0 1 0 1]\n",
      " [0 1 0 1 1 1]\n",
      " [1 0 1 0 1 0]]\n",
      "0    send us your password\n",
      "1      send us your review\n",
      "2     review your password\n",
      "3                review us\n",
      "4       send your password\n",
      "5    send us your password\n",
      "6            review us now\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "df2['message'] = df2['message'].apply(lambda x: ' '.join(x))\n",
    "df3['message'] = df3['message'].apply(lambda x: ' '.join(x))\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "print(\"Counts and messages for the example 13.1\")\n",
    "counts = count_vect.fit_transform(df['message'])\n",
    "print(count_vect.get_feature_names())\n",
    "print(counts.toarray())\n",
    "print(df['message'])\n",
    "\n",
    "print(\"\\n Counts and messages for the example 13.10\")\n",
    "counts2 = count_vect.fit_transform(df2['message'])\n",
    "print(count_vect.get_feature_names())\n",
    "print(counts2.toarray())\n",
    "print(df2['message'])\n",
    "\n",
    "print(\"\\n Counts and messages for the example spam detection\")\n",
    "counts3 = count_vect.fit_transform(df3['message'])\n",
    "print(count_vect.get_feature_names())\n",
    "print(counts3.toarray())\n",
    "print(df3['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer().fit(counts)\n",
    "counts = transformer.transform(counts)\n",
    "transformer2 = TfidfTransformer().fit(counts2)\n",
    "counts2 = transformer2.transform(counts2)\n",
    "transformer3 = TfidfTransformer().fit(counts3)\n",
    "counts3 = transformer3.transform(counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(counts, df['label'], test_size=.1)\n",
    "x_train = counts[:4]\n",
    "x_test = counts[4:5]\n",
    "y_train = pd.Series(df.get_values()[0:4][:,0])\n",
    "y_test = pd.Series(df.get_values()[4:5][:,0])\n",
    "\n",
    "x_train2 = counts2[:4]\n",
    "x_test2 = counts2[4:5]\n",
    "y_train2 = pd.Series(df2.get_values()[0:4][:,0])\n",
    "y_test2 = pd.Series(df2.get_values()[4:5][:,0])\n",
    "\n",
    "x_train3 = counts3[:6]\n",
    "x_test3 = counts3[6:7]\n",
    "y_train3 = pd.Series(df3.get_values()[0:6][:,0])\n",
    "y_test3 = pd.Series(df3.get_values()[6:7][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the example 13.1. The sample is \"chines chines chines tokyo japan\"\n",
      "Predicted class: ['China']\n",
      "Probabilities for each class: [[0.67804117 0.32195883]]\n",
      "\n",
      " Results for the example 13.10. The sample is \"taiwan taiwan sapporo\"\n",
      "Predicted class: ['Not China']\n",
      "Probabilities for each class: [[0.46597316 0.53402684]]\n",
      "\n",
      " Results for the example spam detection. The sample is \"review us now\"\n",
      "Predicted class: ['spam']\n",
      "Probabilities for each class: [[0.41671911 0.58328089]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "print(\"Results for the example 13.1. The sample is \\\"\" + str(df['message'][4])+ \"\\\"\")\n",
    "print(\"Predicted class: \" + str(predicted))\n",
    "print(\"Probabilities for each class: \" + str(model.predict_proba(x_test)))\n",
    "\n",
    "model.fit(x_train2, y_train2)\n",
    "predicted2 = model.predict(x_test2)\n",
    "print(\"\\n Results for the example 13.10. The sample is \\\"\" + str(df2['message'][4])+ \"\\\"\")\n",
    "print(\"Predicted class: \" + str(predicted2))\n",
    "print(\"Probabilities for each class: \" + str(model.predict_proba(x_test2)))\n",
    "\n",
    "model.fit(x_train3, y_train3)\n",
    "predicted3 = model.predict(x_test3)\n",
    "print(\"\\n Results for the example spam detection. The sample is \\\"\" + str(df3['message'][6]) + \"\\\"\")\n",
    "print(\"Predicted class: \" + str(predicted3))\n",
    "print(\"Probabilities for each class: \" + str(model.predict_proba(x_test3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
